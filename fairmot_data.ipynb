{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from IPython.display import Video\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is done now! Huraaaa!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dict which maps player ID from a game to its unique ID in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class is  398\n",
      "The number of dirs is  40\n"
     ]
    }
   ],
   "source": [
    "anno_dirs = glob.glob('../data/raw_data/*')\n",
    "\n",
    "id_dict = {}\n",
    "k_class = 1\n",
    "for anno_dir in anno_dirs:\n",
    "    id_dict[os.path.basename(anno_dir)] = {}\n",
    "    \n",
    "    curr_set = set()\n",
    "    all_jsons = sorted(glob.glob(anno_dir + '/*.json'))\n",
    "    for single_json in all_jsons:\n",
    "        data = json.load(open(single_json))\n",
    "\n",
    "        for i in range(len(data['shapes'])):\n",
    "            curr_set.add(data['shapes'][i]['label'])\n",
    "            \n",
    "    num_classes = len(curr_set)\n",
    "    curr_classes = sorted(list(curr_set))\n",
    "    \n",
    "    en = 0\n",
    "    while en<num_classes:\n",
    "        \n",
    "        id_dict[os.path.basename(anno_dir)][curr_classes[en]] = k_class\n",
    "        en += 1\n",
    "        k_class += 1\n",
    "        \n",
    "print(\"The number of class is \", k_class)\n",
    "print(\"The number of dirs is \", len(anno_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create gt.txt for each video. IMPORTANT! Frames should start from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create gt.txt with team label having only {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd58db9456dc414fb8d527827533dc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24,)\n",
      "Counter({0: 1107, 1: 875})\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'post_process_cls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e3acbb14129f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mteam_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_to_cls_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_team_color_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manno_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_jsons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mgt_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7cfbc8987b84>\u001b[0m in \u001b[0;36mget_team_color_labels\u001b[0;34m(anno_dir, all_jsons)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mkm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"k-means++\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_hists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mproc_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_to_cls_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_process_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_to_cls_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'post_process_cls' is not defined"
     ]
    }
   ],
   "source": [
    "gt_list = []\n",
    "anno_dirs = glob.glob('../data/raw_data/*')\n",
    "\n",
    "\n",
    "for anno_dir in tqdm(anno_dirs):\n",
    "    all_jsons = sorted(glob.glob(anno_dir + '/*.json'))\n",
    "    \n",
    "    \n",
    "    team_cls, id_to_cls_val = get_team_color_labels(anno_dir, all_jsons)\n",
    "    \n",
    "    gt_list = []\n",
    "    cls_en = 0\n",
    "    for en, single_json in enumerate(all_jsons):\n",
    "        data = json.load(open(single_json))\n",
    "\n",
    "        for i in range(len(data['shapes'])):\n",
    "            bbox = data['shapes'][i]['points']  \n",
    "            label = data['shapes'][i]['label']\n",
    "            \n",
    "            player_lbl = id_to_cls_val[label]\n",
    "            \n",
    "            if bbox[0][0] > bbox[1][0] or bbox[0][1] > bbox[1][1]: \n",
    "                print(\"BBOX ERROR\")\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            anno_line = [en+1, id_dict[os.path.basename(anno_dir)][label], \n",
    "                         int(bbox[0][0]), int(bbox[0][1]), \n",
    "                         int(bbox[1][0] - bbox[0][0]), int(bbox[1][1] - bbox[0][1]),\n",
    "                         1, 1, player_lbl]\n",
    "\n",
    "            anno_str = ','.join([str(x) for x in anno_line])     \n",
    "\n",
    "            gt_list.append(anno_str)\n",
    "           \n",
    "        \n",
    "    ### Create the output GT dir\n",
    "    output_dir = os.path.join('../data/mot_data/images/train/', os.path.basename(anno_dir))\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_dir = os.path.join(output_dir, 'gt')\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "    ### Write the detection to the file gt.txt\n",
    "    with open(os.path.join(output_dir, 'gt.txt'), 'w') as f:\n",
    "        for x in gt_list:\n",
    "            f.writelines(x + '\\n')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create gt.txt with all teams having its own label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering all teams in progress...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fabea1b8c014b9abda2c99848a38810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../data/raw_data/2020.02.13-Colorado_at_Oregon Counter({0: 1000, 1: 982}) 0.15113350125944583\n",
      "1 ../data/raw_data/2018.11.27-Indiana_at_Duke Counter({0: 970, 1: 924}) 0.0\n",
      "2 ../data/raw_data/2019-02-11_Virginia_at_North_Carolina Counter({0: 1232, 1: 527}) 0.0\n",
      "3 ../data/raw_data/2020.02.22-Michigan_at_Purdue Counter({0: 1275, 1: 542}) 0.0\n",
      "4 ../data/raw_data/2019.01.22-Duke_at_Pittsburgh Counter({0: 1000, 1: 954}) 0.051150895140664954\n",
      "5 ../data/raw_data/2020.02.25-NorthCarolinaState_at_NorthCarolina Counter({0: 988, 1: 952}) 0.0\n",
      "6 ../data/raw_data/2019.02.26-Duke_at_VirginiaTech Counter({1: 1112, 0: 761}) 0.0\n",
      "7 ../data/raw_data/2019.03.14-ACC-Syracuse_at_Duke Counter({0: 882, 1: 842}) 0.0\n",
      "8 ../data/raw_data/2020.02.15-NotreDame_at_Duke Counter({1: 1005, 0: 730}) 0.0576036866359447\n",
      "9 ../data/raw_data/2020.02.04-Duke_at_BostonCollege Counter({1: 939, 0: 919}) 0.0\n",
      "10 ../data/raw_data/2020.02.10-FloridaState_at_Duke Counter({1: 976, 0: 711}) 0.0\n",
      "11 ../data/raw_data/2020-02-15-Virginia_at_NorthCarolina Counter({0: 954, 1: 636}) 0.0\n",
      "12 ../data/raw_data/2020.01.18-Louisville_at_Duke Counter({0: 864, 1: 864}) 0.0\n",
      "13 ../data/raw_data/2020.01.21-MiamiFL_at_Duke Counter({0: 1081, 1: 684}) 0.05662514156285391\n",
      "14 ../data/raw_data/2018-11-28_Virginia_at_Maryland Counter({1: 985, 0: 899}) 0.0\n",
      "15 ../data/raw_data/2020.02.01-Duke_at_Syracuse Counter({0: 837, 1: 661}) 0.0\n",
      "16 ../data/raw_data/2019.02.16-NorthCarolinaState_at_Duke Counter({0: 809, 1: 775}) 0.0\n",
      "17 ../data/raw_data/2019.02.09_Florida_at_Tennessee Counter({0: 119, 1: 80}) 0.0\n",
      "18 ../data/raw_data/2019.11.29-Oregon_at_NorthCarolina Counter({1: 491, 0: 480}) 0.0\n",
      "19 ../data/raw_data/2020.01.28-Pittsburgh_at_Duke Counter({0: 1248, 1: 516}) 0.0\n",
      "20 ../data/raw_data/2019-02-18_Virginia_at_VirginiaTech Counter({1: 858, 0: 823}) 0.0\n",
      "21 ../data/raw_data/2020.01.25_Baylor_at_Florida Counter({0: 1307, 1: 569}) 0.0\n",
      "22 ../data/raw_data/2020.01.07-Kentucky_at_Georgia Counter({0: 979, 1: 975}) 0.0\n",
      "23 ../data/raw_data/2020.01.27-NorthCarolina_at_NorthCarolinaState Counter({1: 891, 0: 822}) 0.0\n",
      "24 ../data/raw_data/2020.02.20-Oregon_at_ArizonaState Counter({0: 968, 1: 909}) 0.0\n",
      "25 ../data/raw_data/2019.11.28-NorthCarolina_at_Michigan Counter({0: 849, 1: 694}) 0.0\n",
      "26 ../data/raw_data/2020.02.08-Duke_at_NorthCarolina Counter({0: 1154, 1: 788}) 0.0\n",
      "27 ../data/raw_data/2019.01.05-Clemson_at_Duke Counter({0: 922, 1: 913}) 0.0\n",
      "28 ../data/raw_data/2019-02-25_NotreDame_at_FloridaState Counter({0: 1295, 1: 537}) 0.0\n",
      "29 ../data/raw_data/2019-01-19_Virginia_at_Duke Counter({0: 1261, 1: 548}) 0.0\n",
      "30 ../data/raw_data/2019-03-09_Louisville_at_Virginia Counter({1: 963, 0: 880}) 0.0\n",
      "31 ../data/raw_data/2020.01.18-Kentucky_at_Arkansas Counter({0: 995, 1: 953}) 0.0\n",
      "32 ../data/raw_data/2020-01-11_Syracuse_at_Virginia Counter({1: 1334, 0: 585}) 0.0\n",
      "33 ../data/raw_data/2019.02.09_Duke_at_Virginia Counter({0: 155, 1: 121}) 0.0\n",
      "34 ../data/raw_data/2020.01.18-NorthCarolina_at_Pittsburgh Counter({1: 859, 0: 514}) 0.0\n",
      "35 ../data/raw_data/2019-03-04_Virginia_at_Syracuse Counter({0: 819, 1: 791}) 0.0\n",
      "36 ../data/raw_data/2020-02-06 UCLA @ ASU FULL Counter({1: 984, 0: 978}) 0.0\n",
      "37 ../data/raw_data/2020.01.04-Duke_at_MiamiFL Counter({1: 352, 0: 225}) 0.0\n",
      "38 ../data/raw_data/2019-01-12_Tennessee_at_Florida Counter({1: 960, 0: 933}) 0.0\n",
      "39 ../data/raw_data/2020.02.03-NorthCarolina_at_FloridaState Counter({1: 1162, 0: 779}) 0.0\n",
      "\n",
      "Clustering is finished!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e70c8f861349fc9dbabc2946c83b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gt_list = []\n",
    "anno_dirs = glob.glob('../data/raw_data/*')\n",
    "\n",
    "_, id_to_cls_val = get_all_team_classes(id_dict)\n",
    "\n",
    "\n",
    "for anno_dir in tqdm(anno_dirs):\n",
    "    all_jsons = sorted(glob.glob(anno_dir + '/*.json'))\n",
    "\n",
    "    \n",
    "    gt_list = []\n",
    "    cls_en = 0\n",
    "    for en, single_json in enumerate(all_jsons):\n",
    "        data = json.load(open(single_json))\n",
    "\n",
    "        for i in range(len(data['shapes'])):\n",
    "            bbox = data['shapes'][i]['points']  \n",
    "            label = data['shapes'][i]['label']\n",
    "            \n",
    "            if bbox[0][0] > bbox[1][0] or bbox[0][1] > bbox[1][1]: \n",
    "                continue\n",
    "                \n",
    "            track_label = id_dict[os.path.basename(anno_dir)][label]\n",
    "            player_lbl = id_to_cls_val[track_label]\n",
    "            \n",
    "            \n",
    "            anno_line = [en+1, track_label, \n",
    "                         int(bbox[0][0]), int(bbox[0][1]), \n",
    "                         int(bbox[1][0] - bbox[0][0]), int(bbox[1][1] - bbox[0][1]),\n",
    "                         1, 1, player_lbl]\n",
    "\n",
    "            anno_str = ','.join([str(x) for x in anno_line])     \n",
    "\n",
    "            gt_list.append(anno_str)\n",
    "           \n",
    "        \n",
    "    ### Create the output GT dir\n",
    "    output_dir = os.path.join('../data/mot_data/images/train/', os.path.basename(anno_dir))\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_dir = os.path.join(output_dir, 'gt')\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "    ### Write the detection to the file gt.txt\n",
    "    with open(os.path.join(output_dir, 'gt.txt'), 'w') as f:\n",
    "        for x in gt_list:\n",
    "            f.writelines(x + '\\n')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANNO FORMAT\n",
    "### frame_number obj_ID x y width height 1 (conf score) 1 (obj type) visibility_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy frames to mot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To understand which frame to copy, we need to create the set of all available frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "anno_dirs = glob.glob('../data/raw_data/*')\n",
    "\n",
    "set_of_all = set()\n",
    "for anno_dir in anno_dirs:\n",
    "    all_jsons = sorted(glob.glob(anno_dir + '/*.json'))\n",
    "    for js in all_jsons:\n",
    "        x = '/'.join(js.split('/')[-2:])\n",
    "        set_of_all.add(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "all_dirs = glob.glob('../data/mot_data/images/train/*')\n",
    "orig_frames = os.listdir('../../data/player_tracking_frames')\n",
    "\n",
    "\n",
    "for dr in all_dirs:\n",
    "    \n",
    "    if os.path.basename(dr) in orig_frames:\n",
    "        orig_dir = os.path.join('../../data/player_tracking_frames', os.path.basename(dr))\n",
    "\n",
    "        dest_dir = os.path.join(dr, 'img1')\n",
    "        \n",
    "        \n",
    "        if os.path.exists(dest_dir):\n",
    "            if not os.path.isdir(dest_dir):\n",
    "                os.remove(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "all_dirs = glob.glob('../data/mot_data/images/train/*')\n",
    "orig_frames = os.listdir('../../data/player_tracking_frames')\n",
    "\n",
    "\n",
    "for dr in all_dirs:\n",
    "    \n",
    "    if os.path.basename(dr) in orig_frames:\n",
    "        orig_dir = os.path.join('../../data/player_tracking_frames', os.path.basename(dr))\n",
    "\n",
    "        dest_dir = os.path.join(dr, 'img1')\n",
    "\n",
    "        if os.path.exists(dest_dir):\n",
    "            shutil.rmtree(dest_dir)\n",
    "            os.makedirs(dest_dir)\n",
    "        else:\n",
    "            os.makedirs(dest_dir)\n",
    "        \n",
    "        curr_imgs = glob.glob(orig_dir + '/*.jpg')\n",
    "        for img in curr_imgs:\n",
    "            x = '/'.join(img.split('/')[-2:]).replace('.jpg', '.json')\n",
    "            if x in set_of_all:\n",
    "                shutil.copy2(img, dest_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename image files. IMPORTANT! Frames should start from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dirs = glob.glob('../data/mot_data/images/train/*')\n",
    "\n",
    "for dr in all_dirs:\n",
    "    img_dr = os.path.join(dr, 'img1')\n",
    "    curr_imgs = sorted(glob.glob(img_dr + '/*.jpg'))\n",
    "    \n",
    "    for en, img_path in enumerate(curr_imgs):\n",
    "        base = os.path.basename(img_path)\n",
    "        new_base = f\"{en+1:06d}.jpg\"\n",
    "        os.rename(img_path, img_path.replace(base, new_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom.train file, don't know why :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 4\n",
      "6507\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "all_dirs = glob.glob('../data/mot_data/images/train/*')\n",
    "all_dirs = sorted(all_dirs)\n",
    "\n",
    "\n",
    "train_dirs = all_dirs[:int(0.9*len(all_dirs))]\n",
    "val_dirs = all_dirs[int(0.9*len(all_dirs)):]\n",
    "print(len(train_dirs), len(val_dirs))\n",
    "\n",
    "output = []\n",
    "for dr in train_dirs:\n",
    "    curr_files = sorted(glob.glob(dr + '/img1/*.jpg'))\n",
    "    for f in curr_files:\n",
    "        output.append(f.replace('../data/', ''))\n",
    "             \n",
    "with open('./src/data/custom.train', 'w') as f:\n",
    "    for l in output:\n",
    "        f.writelines(l + '\\n')\n",
    "        \n",
    "print(len(output))\n",
    "        \n",
    "\n",
    "output = []\n",
    "for dr in val_dirs:\n",
    "    curr_files = sorted(glob.glob(dr + '/img1/*.jpg'))\n",
    "    for f in curr_files:\n",
    "        output.append(f.replace('../data/', ''))\n",
    "             \n",
    "with open('./src/data/custom.val', 'w') as f:\n",
    "    for l in output:\n",
    "        f.writelines(l + '\\n')\n",
    "        \n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/mot_data/images/train/2020.02.15-NotreDame_at_Duke',\n",
       " '../data/mot_data/images/train/2020.02.20-Oregon_at_ArizonaState',\n",
       " '../data/mot_data/images/train/2020.02.22-Michigan_at_Purdue',\n",
       " '../data/mot_data/images/train/2020.02.25-NorthCarolinaState_at_NorthCarolina']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cfg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = {}\n",
    "\n",
    "# cfg['root'] = '/home/ubuntu/oljike/PlayerTracking/data'\n",
    "# cfg['train'] = {}\n",
    "# cfg['train']['custom'] = './data/custom.train'\n",
    "# cfg['train']['test_emb'] = './data/custom.val'\n",
    "# cfg['train']['test'] = './data/custom.val'\n",
    "\n",
    "# with open('src/lib/cfg/custom.json','w') as f:\n",
    "#     json.dump(cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "\n",
    "cfg['root'] = '/home/ubuntu/oljike/PlayerTracking/data'\n",
    "cfg['train'] = {}\n",
    "cfg['train']['custom'] = './data/custom.train'\n",
    "cfg['test'] = {}\n",
    "cfg['test']['custom'] = './data/custom.val'\n",
    "cfg['test_emb'] = './data/custom.val'\n",
    "\n",
    "\n",
    "with open('src/lib/cfg/custom.json','w') as f:\n",
    "    json.dump(cfg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create team color labels and check them visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_team_color_labels(anno_dir, all_jsons):\n",
    "    all_labels = []\n",
    "    all_hists = []\n",
    "\n",
    "    \n",
    "    orig_dir = os.path.join('../../data/player_tracking_frames', os.path.basename(anno_dir))\n",
    "    for single_json in all_jsons:\n",
    "        data = json.load(open(single_json))\n",
    "\n",
    "        ### Read the image\n",
    "        img_path = os.path.join(orig_dir, os.path.basename(single_json).replace('.json', '.jpg')) \n",
    "        img0 = cv2.imread(img_path)\n",
    "        h,w,_ = img0.shape\n",
    "\n",
    "        for i in range(len(data['shapes'])):\n",
    "            pts = np.array(data['shapes'][i]['points']).astype(int)\n",
    "\n",
    "            if pts[0][1] > pts[1][1] or pts[0][0] > pts[1][0]: continue\n",
    "            center_y = int((pts[1][1] + pts[0][1]) / 2)\n",
    "            center_x = int((pts[1][0] + pts[0][0]) / 2)\n",
    "\n",
    "            img_box = img0[max(0,center_y - 30): min(h, center_y + 30), \n",
    "                           max(0, center_x - 10): min(w, center_x + 10), :]\n",
    "            cv2.imwrite('small.jpg', img_box)\n",
    "\n",
    "            img_box = cv2.cvtColor(img_box, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            hist = cv2.calcHist([img_box], [0], None, [24],\n",
    "                                [0, 300])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "            all_hists.append(hist)\n",
    "            all_labels.append(data['shapes'][i]['label'])\n",
    "\n",
    "    concat_hists = np.concatenate(all_hists)\n",
    "    print(hist.shape)\n",
    "    km = KMeans(n_clusters=2, init=\"k-means++\", max_iter=10000).fit(all_hists)\n",
    "    print(Counter(km.labels_))\n",
    "    proc_cls, id_to_cls_val = post_process_cls(km.labels_, all_labels)\n",
    "    print(Counter(proc_cls))\n",
    "    return proc_cls, id_to_cls_val\n",
    "\n",
    "\n",
    "\n",
    "# anno_dir = glob.glob('../data/raw_data/*')[24]\n",
    "# all_jsons = sorted(glob.glob(anno_dir + '/*.json'))\n",
    "# proc_cls, id_to_cls_val = get_team_color_labels(anno_dir, all_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "h, w, _ = 720, 1280, 0\n",
    "out = cv2.VideoWriter('team_label_output.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 3, (w,h))\n",
    "\n",
    "orig_dir = os.path.join('../../data/player_tracking_frames', os.path.basename(anno_dir))\n",
    "\n",
    "en = 0\n",
    "for single_json in all_jsons:\n",
    "    data = json.load(open(single_json))\n",
    "    \n",
    "    ### Read the image\n",
    "    img_path = os.path.join(orig_dir, os.path.basename(single_json).replace('.json', '.jpg')) \n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    for shape in data['shapes']:\n",
    "        bbox = np.array([[int(x) for x in y] for y in shape['points']])\n",
    "        \n",
    "        bbox = bbox.flatten()\n",
    "   \n",
    "        color = get_color(id_to_cls_val[shape['label']])\n",
    "        \n",
    "        cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, thickness=1)\n",
    "        cv2.putText(img, shape['label'], (bbox[0], max(0, bbox[1] - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), thickness=1)\n",
    "       \n",
    "        en += 1\n",
    "    out.write(img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video('team_label_output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_color(lbl):\n",
    "\n",
    "    if lbl==0:\n",
    "        return (0,0,255)\n",
    "    elif lbl==1:\n",
    "        return (0,255,0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def post_process_cls(all_cls, all_tracks):\n",
    "\n",
    "    ### First, we need to get the set of all the tracks\n",
    "    ### After which, to find its corrsponding classes\n",
    "    ### And transform/interpolate the classes list\n",
    "    from collections import Counter\n",
    "    id_to_cls_list = {}\n",
    "    for en, (cls, track_id) in enumerate(zip(all_cls, all_tracks)):\n",
    "\n",
    "        if track_id in id_to_cls_list:\n",
    "            id_to_cls_list[track_id].append(cls)\n",
    "        else:\n",
    "            id_to_cls_list[track_id] = [cls]\n",
    "            \n",
    "\n",
    "    id_to_cls_val = {}\n",
    "    for track_id, cls_lst in id_to_cls_list.items():\n",
    "        cls_lst = np.array(cls_lst).flatten().tolist()\n",
    "        cnt = Counter(cls_lst)\n",
    "        mst_cmn = cnt.most_common()[0][0]\n",
    "        id_to_cls_val[track_id] = int(mst_cmn)\n",
    "\n",
    "    output = []\n",
    "    for en, track_id in enumerate(all_tracks):\n",
    "        \n",
    "        output.append(id_to_cls_val[track_id])\n",
    "\n",
    "    return output, id_to_cls_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create color classes for all teams in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually this thing should return a dict where the key correspond to its global class number and the value is the color class defined by the global clusterizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_all_team_classes(id_dict):\n",
    "    print(\"Clustering all teams in progress...\")\n",
    "    anno_dirs = glob.glob('../data/raw_data/*')\n",
    "    \n",
    "    ### Create global dict which maps global player track to its new global team class\n",
    "    global_id_to_cls_val = {}\n",
    "    all_cls = list(range(0, 2 * len(anno_dirs)))\n",
    "\n",
    "    def chunks(l, n):\n",
    "        n = max(1, n)\n",
    "        return [l[i:i+n] for i in range(0, len(l), n)]   \n",
    "    cls_chunks = chunks(all_cls, 2)  \n",
    "\n",
    "\n",
    "    for anno_en, anno_dir in enumerate(tqdm(anno_dirs)):\n",
    "        \n",
    "        ### Process a new game\n",
    "        all_jsons = sorted(glob.glob(anno_dir + '/*.json'))\n",
    "        orig_dir = os.path.join('../../data/player_tracking_frames', os.path.basename(anno_dir))\n",
    "        \n",
    "        ### Create the corresponding history of labels and histograms\n",
    "        all_hists = []\n",
    "        all_labels = []\n",
    "        \n",
    "        anno_error = 0\n",
    "        box_cnt = 0\n",
    "        for en, single_json in enumerate(all_jsons):\n",
    "            data = json.load(open(single_json))\n",
    "            \n",
    "            \n",
    "            img_path = os.path.join(orig_dir, os.path.basename(single_json).replace('.json', '.jpg')) \n",
    "            img0 = cv2.imread(img_path)\n",
    "            h,w,_ = img0.shape\n",
    "\n",
    "            for i in range(len(data['shapes'])):\n",
    "                box_cnt += 1\n",
    "            \n",
    "                label = data['shapes'][i]['label']\n",
    "                pts = np.array(data['shapes'][i]['points']).astype(int)\n",
    "                if pts[0][1] > pts[1][1] or pts[0][0] > pts[1][0]: \n",
    "                    anno_error += 1\n",
    "                    continue\n",
    "\n",
    "                player_label = id_dict[os.path.basename(anno_dir)][label]\n",
    "                \n",
    "                center_y = int((pts[1][1] + pts[0][1]) / 2)\n",
    "                center_x = int((pts[1][0] + pts[0][0]) / 2)\n",
    "\n",
    "                img_box = img0[max(0,center_y - 30): min(h, center_y + 30), \n",
    "                               max(0, center_x - 10): min(w, center_x + 10), :]\n",
    "\n",
    "                img_box = cv2.cvtColor(img_box, cv2.COLOR_BGR2HSV)\n",
    "                hist = cv2.calcHist([img_box], [0], None, [24],\n",
    "                                [0, 300])\n",
    "                hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "                all_hists.append(hist)\n",
    "                all_labels.append(player_label)\n",
    "                \n",
    "                \n",
    "\n",
    "        concat_hists = np.concatenate(all_hists)\n",
    "        km = KMeans(n_clusters=2, init=\"k-means++\", max_iter=10000).fit(all_hists)\n",
    "        proc_cls, id_to_cls_val = post_process_cls(km.labels_, all_labels)\n",
    "        \n",
    "        print(anno_en, anno_dir, Counter(proc_cls), 100 * (anno_error/box_cnt))\n",
    "        \n",
    "        for player_id, color_cls in id_to_cls_val.items():\n",
    "            curr_cls_subset = cls_chunks[anno_en]\n",
    "            global_id_to_cls_val[player_id] = curr_cls_subset[color_cls]\n",
    "    \n",
    "    print('Clustering is finished!')\n",
    "    return proc_cls, global_id_to_cls_val                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cls = list(range(0, 2 * len(anno_dirs)))\n",
    "\n",
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]   \n",
    "cls_chunks = chunks(all_cls, 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering all teams in progress...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398d3f9d53334f63836101d8aad72a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ../data/raw_data/2019.02.16-NorthCarolinaState_at_Duke Counter({1: 809, 0: 775}) 0.0\n",
      "17 ../data/raw_data/2019.02.09_Florida_at_Tennessee Counter({0: 119, 1: 80}) 0.0\n",
      "18 ../data/raw_data/2019.11.29-Oregon_at_NorthCarolina Counter({1: 491, 0: 480}) 0.0\n",
      "19 ../data/raw_data/2020.01.28-Pittsburgh_at_Duke Counter({0: 1248, 1: 516}) 0.0\n",
      "20 ../data/raw_data/2019-02-18_Virginia_at_VirginiaTech Counter({1: 858, 0: 823}) 0.0\n",
      "21 ../data/raw_data/2020.01.25_Baylor_at_Florida Counter({0: 1307, 1: 569}) 0.0\n",
      "22 ../data/raw_data/2020.01.07-Kentucky_at_Georgia Counter({0: 979, 1: 975}) 0.0\n",
      "23 ../data/raw_data/2020.01.27-NorthCarolina_at_NorthCarolinaState Counter({0: 891, 1: 822}) 0.0\n",
      "24 ../data/raw_data/2020.02.20-Oregon_at_ArizonaState Counter({1: 968, 0: 909}) 0.0\n",
      "25 ../data/raw_data/2019.11.28-NorthCarolina_at_Michigan Counter({0: 849, 1: 694}) 0.0\n",
      "26 ../data/raw_data/UCLA vs Washington 2-15-20 Counter({0: 980, 1: 832}) 0.0\n",
      "27 ../data/raw_data/2020.02.08-Duke_at_NorthCarolina Counter({1: 1154, 0: 788}) 0.0\n",
      "28 ../data/raw_data/2019.01.05-Clemson_at_Duke Counter({0: 922, 1: 913}) 0.0\n",
      "29 ../data/raw_data/2019-02-25_NotreDame_at_FloridaState Counter({0: 1295, 1: 537}) 0.0\n",
      "30 ../data/raw_data/2019-01-19_Virginia_at_Duke Counter({1: 1261, 0: 548}) 0.0\n",
      "31 ../data/raw_data/2019-03-09_Louisville_at_Virginia Counter({1: 963, 0: 880}) 0.0\n",
      "32 ../data/raw_data/2020.01.18-Kentucky_at_Arkansas Counter({0: 995, 1: 953}) 0.0\n",
      "33 ../data/raw_data/2020-01-11_Syracuse_at_Virginia Counter({1: 1334, 0: 585}) 0.0\n",
      "34 ../data/raw_data/2019.02.09_Duke_at_Virginia Counter({0: 155, 1: 121}) 0.0\n",
      "35 ../data/raw_data/2020.01.18-NorthCarolina_at_Pittsburgh Counter({0: 859, 1: 514}) 0.0\n",
      "36 ../data/raw_data/2019-03-04_Virginia_at_Syracuse Counter({1: 819, 0: 791}) 0.0\n",
      "37 ../data/raw_data/2020-02-06 UCLA @ ASU FULL Counter({1: 984, 0: 978}) 0.0\n",
      "38 ../data/raw_data/2020.01.04-Duke_at_MiamiFL Counter({0: 352, 1: 225}) 0.0\n",
      "39 ../data/raw_data/2019-01-12_Tennessee_at_Florida Counter({1: 960, 0: 933}) 0.0\n",
      "40 ../data/raw_data/2020.02.03-NorthCarolina_at_FloridaState Counter({1: 1162, 0: 779}) 0.0\n",
      "\n",
      "Clustering is finished!\n"
     ]
    }
   ],
   "source": [
    "_, id_to_cls_val = get_all_team_classes(id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Visual check\n",
    "h, w, _ = 720, 1280, 0\n",
    "out = cv2.VideoWriter('team_label_output.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 3, (w,h))\n",
    "\n",
    "\n",
    "anno_dir = glob.glob('../data/raw_data/*')[1]\n",
    "all_jsons = sorted(glob.glob(anno_dir + '/*.json'))\n",
    "orig_dir = os.path.join('../../data/player_tracking_frames', os.path.basename(anno_dir))\n",
    "en = 0\n",
    "\n",
    "for single_json in all_jsons:\n",
    "    data = json.load(open(single_json))\n",
    "    \n",
    "    ### Read the image\n",
    "    img_path = os.path.join(orig_dir, os.path.basename(single_json).replace('.json', '.jpg')) \n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    for shape in data['shapes']:\n",
    "        bbox = np.array([[int(x) for x in y] for y in shape['points']])\n",
    "        label = shape['label']\n",
    "        bbox = bbox.flatten()\n",
    "        track_label = id_dict[os.path.basename(anno_dir)][label]\n",
    "        player_lbl = id_to_cls_val[track_label]\n",
    "#         color = get_color(player_lbl)\n",
    "        \n",
    "        cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255,0,0), thickness=1)\n",
    "        cv2.putText(img, str(player_lbl), (bbox[0], max(0, bbox[1] - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), thickness=5)\n",
    "       \n",
    "        en += 1\n",
    "    out.write(img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"team_label_output.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('team_label_output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
